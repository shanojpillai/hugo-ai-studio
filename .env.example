# Frontend Configuration
STREAMLIT_SERVER_PORT=8501
STREAMLIT_SERVER_ADDRESS=0.0.0.0
BACKEND_URL=http://backend:8000

# Backend Configuration
FASTAPI_HOST=0.0.0.0
FASTAPI_PORT=8000
LLM_URL=http://ollama:11434
LLM_MODEL=llama3.2
GENERATED_SITES_PATH=/app/generated_sites

# LLM Model Configuration
MODEL_TEMPERATURE=0.7
MODEL_TOP_P=0.9
MODEL_MAX_TOKENS=2048

# Hugo Configuration
HUGO_WATCH=true
HUGO_THEME_PATH=/app/themes

# Nginx Configuration
NGINX_PORT=8080
SITES_ROOT=/usr/share/nginx/html/sites

# Ollama Configuration
OLLAMA_HOST=0.0.0.0
OLLAMA_PORT=11434
OLLAMA_MODELS_PATH=/root/.ollama

# Nginx Configuration
NGINX_ENTRYPOINT_QUIET_LOGS=1

# Development Settings
DEBUG=false
LOG_LEVEL=INFO
